{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Image segmentation with U-Net\n",
    "Inspired by [this repository](https://)"
   ],
   "metadata": {
    "id": "vTuH68QnVBX0",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setting up"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import dependencies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from model import UNet\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "from evaluate import evaluate\n",
    "from utils.data_loading import BasicDataset, CarvanaDataset\n",
    "from utils.dice_score import dice_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting the GPU device"
   ],
   "metadata": {
    "id": "qjo7hXy4cFWP",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available()\n",
    "    else 'mps' if torch.backends.mps.is_available()\n",
    "    else 'cpu'\n",
    ")"
   ],
   "metadata": {
    "id": "lmZ-xn8EcJVQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining helper functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating dataset from given directories"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def _create_dataset(\n",
    "    image_directory: Path,\n",
    "    mask_directory: Path,\n",
    "    image_scale: float,\n",
    "):\n",
    "    try:\n",
    "        dataset = CarvanaDataset(image_directory, mask_directory, image_scale)\n",
    "    except (AssertionError, RuntimeError, IndexError):\n",
    "        dataset = BasicDataset(image_directory, mask_directory, image_scale)\n",
    "\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Splitting dataset into training and validation sets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def _split_dataset(dataset, validation_percentage: float):\n",
    "    num_validation = int(len(dataset) * validation_percentage)\n",
    "    num_training = len(dataset) - num_validation\n",
    "    training_set, validation_set = random_split(\n",
    "        dataset,\n",
    "        [num_training, num_validation],\n",
    "        generator=torch.Generator().manual_seed(0),\n",
    "    )\n",
    "    return training_set, validation_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating data loaders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def _create_data_loaders(training_set, validation_set, batch_size):\n",
    "    loader_arguments = dict(\n",
    "        batch_size=batch_size,\n",
    "        num_workers=os.cpu_count(),\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    training_loader = DataLoader(\n",
    "        training_set, shuffle=True, **loader_arguments\n",
    "    )\n",
    "    validation_loader = DataLoader(\n",
    "        validation_set, shuffle=False, drop_last=True, **loader_arguments\n",
    "    )\n",
    "    return training_loader, validation_loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Checkpointing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "image_directory = Path('./data/images/')\n",
    "mask_directory = Path('./data/masks/')\n",
    "checkpoint_directory = Path('./checkpoints/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def save_checkpoint(model, dataset, checkpoint_directory, epoch):\n",
    "    Path(checkpoint_directory).mkdir(parents=True, exist_ok=True)\n",
    "    state_dict = model.state_dict()\n",
    "    state_dict['mask_values'] = dataset.mask_values\n",
    "    torch.save(state_dict, str(checkpoint_directory / f'checkpoint_epoch{epoch}.pth'))\n",
    "    logging.info(f'Checkpoint {epoch} saved!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Determining the loss for a batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def _get_batch_loss(model, batch, criterion, automatic_mixed_precision):\n",
    "    images, true_masks = batch['image'], batch['mask']\n",
    "    invalid_shape_message = (\n",
    "        f'Network has been defined with {model.n_channels} input channels, '\n",
    "        f'but loaded images have {images.shape[1]} channels. Please check that '\n",
    "        'the images are loaded correctly.'\n",
    "    )\n",
    "    assert images.shape[1] == model.n_channels, invalid_shape_message\n",
    "    images = images.to(\n",
    "        device=device, dtype=torch.float32, memory_format=torch.channels_last\n",
    "    )\n",
    "    true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "    with torch.autocast(\n",
    "        device.type if device.type != 'mps' else 'cpu',\n",
    "        enabled=automatic_mixed_precision,\n",
    "    ):\n",
    "        predicted_masks = model(images)\n",
    "        if model.n_classes == 1:\n",
    "            loss = criterion(predicted_masks.squeeze(1), true_masks.float())\n",
    "            loss += dice_loss(\n",
    "                F.sigmoid(predicted_masks.squeeze(1)),\n",
    "                true_masks.float(),\n",
    "                multiclass=False,\n",
    "            )\n",
    "        else:\n",
    "            loss = criterion(predicted_masks, true_masks)\n",
    "            loss += dice_loss(\n",
    "                F.softmax(predicted_masks, dim=1).float(),\n",
    "                F.one_hot(true_masks, model.n_classes).permute(0, 3, 1, 2).float(),\n",
    "                multiclass=True\n",
    "            )\n",
    "\n",
    "        return images, loss, true_masks, predicted_masks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logging"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def _initialize_logging(\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    learning_rate,\n",
    "    validation_percentage,\n",
    "    save_checkpoint,\n",
    "    image_scale,\n",
    "    num_training,\n",
    "    num_validation,\n",
    "    automatic_mixed_precision,\n",
    "):\n",
    "    experiment = wandb.init(project='U-Net', resume='allow', anonymous='must')\n",
    "    experiment_config = {\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate,\n",
    "        'val_percent': validation_percentage,\n",
    "        'save_checkpoint': save_checkpoint,\n",
    "        'img_scale': image_scale,\n",
    "        'automatic_mixed_precision': automatic_mixed_precision,\n",
    "    }\n",
    "    experiment.config.update(experiment_config)\n",
    "\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {learning_rate}\n",
    "        Training size:   {num_training}\n",
    "        Validation size: {num_validation}\n",
    "        Checkpoints:     {save_checkpoint}\n",
    "        Device:          {device.type}\n",
    "        Images scaling:  {image_scale}\n",
    "        Mixed Precision: {automatic_mixed_precision}\n",
    "    ''')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def _evaluate(\n",
    "    validation_loader,\n",
    "    epoch,\n",
    "    num_training,\n",
    "    batch_size,\n",
    "    global_step,\n",
    "    scheduler,\n",
    "    optimizer,\n",
    "    images,\n",
    "    true_masks,\n",
    "    predicted_masks,\n",
    "    automatic_mixed_precision,\n",
    "    experiment,\n",
    "):\n",
    "    division_step = (num_training // (5 * batch_size))\n",
    "    if division_step > 0:\n",
    "        if global_step % division_step == 0:\n",
    "            histograms = {}\n",
    "            for tag, value in model.named_parameters():\n",
    "                tag = tag.replace('/', '.')\n",
    "                if not (torch.isinf(value) | torch.isnan(value)).any():\n",
    "                    histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())\n",
    "                if not (torch.isinf(value.grad) | torch.isnan(value.grad)).any():\n",
    "                    histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())\n",
    "\n",
    "            val_score = evaluate(model, validation_loader, device, automatic_mixed_precision)\n",
    "            scheduler.step(val_score)\n",
    "\n",
    "            logging.info(f'Validation Dice score: {val_score}')\n",
    "            try:\n",
    "                experiment.log({\n",
    "                    'learning rate': optimizer.param_groups[0]['lr'],\n",
    "                    'validation Dice': val_score,\n",
    "                    'images': wandb.Image(images[0].cpu()),\n",
    "                    'masks': {\n",
    "                        'true': wandb.Image(true_masks[0].float().cpu()),\n",
    "                        'pred': wandb.Image(predicted_masks.argmax(dim=1)[0].float().cpu()),\n",
    "                    },\n",
    "                    'step': global_step,\n",
    "                    'epoch': epoch,\n",
    "                    **histograms\n",
    "                })\n",
    "            except:\n",
    "                pass\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Putting it together"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 1e-5\n",
    "VALIDATION_PERCENTAGE = 0.1\n",
    "SAVE_CHECKPOINT = True\n",
    "IMAGE_SCALE = 0.5\n",
    "AUTOMATIC_MIXED_PRECISION = False\n",
    "WEIGHT_DECAY = 1e-8\n",
    "MOMENTUM = 0.999\n",
    "GRADIENT_CLIPPING = 1.0\n",
    "\n",
    "BILINEAR = True\n",
    "N_CHANNELS = 3  # for RGB images\n",
    "N_CLASSES = 2  # the number of probabilities you want to get per pixel\n",
    "\n",
    "STATE_DICT_PATH = ''\n",
    "LOAD_STATE_DICT = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using device mps\n",
      "INFO: Network:\n",
      "\t3 input channels\n",
      "\t2 output channels (classes)\n",
      "\tBilinear upscaling\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "model = UNet(n_channels=N_CHANNELS, n_classes=N_CLASSES, bilinear=BILINEAR)\n",
    "model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "logging.info(\n",
    "    f'Network:\\n'\n",
    "     f'\\t{model.n_channels} input channels\\n'\n",
    "     f'\\t{model.n_classes} output channels (classes)\\n'\n",
    "     f'\\t{\"Bilinear\" if model.bilinear else \"Transposed conv\"} upscaling'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "if LOAD_STATE_DICT:\n",
    "    state_dict = torch.load(STATE_DICT_PATH, map_location=device)\n",
    "    del state_dict['mask_values']\n",
    "    model.load_state_dict(state_dict)\n",
    "    logging.info(f'Model loaded from {STATE_DICT_PATH}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "UNet(\n  (inc): DoubleConvolution(\n    (double_convolution): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (down1): Downscaling(\n    (maxpool_convolution): Sequential(\n      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConvolution(\n        (double_convolution): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (down2): Downscaling(\n    (maxpool_convolution): Sequential(\n      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConvolution(\n        (double_convolution): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (down3): Downscaling(\n    (maxpool_convolution): Sequential(\n      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConvolution(\n        (double_convolution): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (down4): Downscaling(\n    (maxpool_convolution): Sequential(\n      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConvolution(\n        (double_convolution): Sequential(\n          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (up1): Upscaling(\n    (upsample): Upsample(scale_factor=2.0, mode='bilinear')\n    (convolution): DoubleConvolution(\n      (double_convolution): Sequential(\n        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (up2): Upscaling(\n    (upsample): Upsample(scale_factor=2.0, mode='bilinear')\n    (convolution): DoubleConvolution(\n      (double_convolution): Sequential(\n        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (up3): Upscaling(\n    (upsample): Upsample(scale_factor=2.0, mode='bilinear')\n    (convolution): DoubleConvolution(\n      (double_convolution): Sequential(\n        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (up4): Upscaling(\n    (upsample): Upsample(scale_factor=2.0, mode='bilinear')\n    (convolution): DoubleConvolution(\n      (double_convolution): Sequential(\n        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (out_convolution): OutConvolution(\n    (convolution): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n  )\n)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Creating dataset with 5088 examples\n",
      "INFO: Scanning mask files to determine unique values\n",
      "100%|██████████| 5088/5088 [00:33<00:00, 152.99it/s]\n",
      "INFO: Unique mask values: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "dataset = _create_dataset(image_directory, mask_directory, IMAGE_SCALE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "training_set, validation_set = _split_dataset(dataset, VALIDATION_PERCENTAGE)\n",
    "num_training = len(training_set)\n",
    "num_validation = len(validation_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "training_loader, validation_loader = _create_data_loaders(\n",
    "    training_set, validation_set, BATCH_SIZE\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configuring the training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33manony-moose-855306159078586455\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.12"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/paripasviktor/ltu/adm/project/wandb/run-20231110_235122-fptyimu3</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/anony-moose-855306159078586455/U-Net/runs/fptyimu3?apiKey=02f5d3f7ecf5505148704f09b3e8bf8c9d10b6ad' target=\"_blank\">bright-spaceship-4</a></strong> to <a href='https://wandb.ai/anony-moose-855306159078586455/U-Net?apiKey=02f5d3f7ecf5505148704f09b3e8bf8c9d10b6ad' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/anony-moose-855306159078586455/U-Net?apiKey=02f5d3f7ecf5505148704f09b3e8bf8c9d10b6ad' target=\"_blank\">https://wandb.ai/anony-moose-855306159078586455/U-Net?apiKey=02f5d3f7ecf5505148704f09b3e8bf8c9d10b6ad</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/anony-moose-855306159078586455/U-Net/runs/fptyimu3?apiKey=02f5d3f7ecf5505148704f09b3e8bf8c9d10b6ad' target=\"_blank\">https://wandb.ai/anony-moose-855306159078586455/U-Net/runs/fptyimu3?apiKey=02f5d3f7ecf5505148704f09b3e8bf8c9d10b6ad</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Do NOT share these links with anyone. They can be used to claim your runs."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Starting training:\n",
      "        Epochs:          5\n",
      "        Batch size:      1\n",
      "        Learning rate:   1e-05\n",
      "        Training size:   4580\n",
      "        Validation size: 508\n",
      "        Checkpoints:     True\n",
      "        Device:          mps\n",
      "        Images scaling:  0.5\n",
      "        Mixed Precision: False\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x1681f9f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 1681fa1d0, execution_count=19 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 1657e03d0, raw_cell=\"experiment = _initialize_logging(\n",
      "    EPOCHS,\n",
      "    ..\" store_history=True silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;31mTypeError\u001B[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "experiment = _initialize_logging(\n",
    "    EPOCHS,\n",
    "    BATCH_SIZE,\n",
    "    LEARNING_RATE,\n",
    "    VALIDATION_PERCENTAGE,\n",
    "    SAVE_CHECKPOINT,\n",
    "    IMAGE_SCALE,\n",
    "    num_training,\n",
    "    num_validation,\n",
    "    AUTOMATIC_MIXED_PRECISION,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x1681f9f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 16551ee10, raw_cell=\"optimizer = optim.RMSprop(\n",
      "    model.parameters(),..\" store_history=True silent=False shell_futures=True cell_id=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;31mTypeError\u001B[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x1681f9f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 16820da90, execution_count=20 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 16551ee10, raw_cell=\"optimizer = optim.RMSprop(\n",
      "    model.parameters(),..\" store_history=True silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;31mTypeError\u001B[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "optimizer = optim.RMSprop(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    momentum=MOMENTUM,\n",
    "    foreach=True,\n",
    ")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, 'max', patience=5\n",
    ")\n",
    "grad_scaler = torch.cuda.amp.GradScaler(enabled=AUTOMATIC_MIXED_PRECISION)\n",
    "criterion = torch.nn.CrossEntropyLoss() if model.n_classes > 1 else torch.nn.BCEWithLogitsLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x1681f9f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 16b44de10, raw_cell=\"\n",
      "global_step = 0\n",
      "for epoch in range(1, EPOCHS + 1)..\" store_history=True silent=False shell_futures=True cell_id=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;31mTypeError\u001B[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/4580 [00:01<?, ?img/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/paripasviktor/ltu/adm/venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/paripasviktor/ltu/adm/venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/paripasviktor/ltu/adm/venv/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 364, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/paripasviktor/ltu/adm/venv/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 364, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"/Users/paripasviktor/ltu/adm/project/utils/data_loading.py\", line 108, in __getitem__\n    mask = self.preprocess(self.mask_values, mask, self.scale, is_mask=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/paripasviktor/ltu/adm/project/utils/data_loading.py\", line 124, in preprocess\n    return self._mask(image, new_size, mask_values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/paripasviktor/ltu/adm/project/utils/data_loading.py\", line 141, in _mask\n    mask[image == value] = i\n    ~~~~^^^^^^^^^^^^^^^^\nIndexError: boolean index did not match indexed array along dimension 0; dimension is 959 but corresponding boolean dimension is 640\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 8\u001B[0m\n\u001B[1;32m      4\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tqdm(\n\u001B[1;32m      6\u001B[0m     total\u001B[38;5;241m=\u001B[39mnum_training, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mEPOCHS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimg\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      7\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m progress_bar:\n\u001B[0;32m----> 8\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtraining_loader\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrue_masks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredicted_masks\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m_get_batch_loss\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mAUTOMATIC_MIXED_PRECISION\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzero_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mset_to_none\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ltu/adm/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/ltu/adm/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1345\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1343\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1344\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info[idx]\n\u001B[0;32m-> 1345\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ltu/adm/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1371\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._process_data\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1369\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_put_index()\n\u001B[1;32m   1370\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ExceptionWrapper):\n\u001B[0;32m-> 1371\u001B[0m     \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1372\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/ltu/adm/venv/lib/python3.11/site-packages/torch/_utils.py:694\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    690\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    691\u001B[0m     \u001B[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001B[39;00m\n\u001B[1;32m    692\u001B[0m     \u001B[38;5;66;03m# instantiate since we don't know how to\u001B[39;00m\n\u001B[1;32m    693\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 694\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[0;31mIndexError\u001B[0m: Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/paripasviktor/ltu/adm/venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/paripasviktor/ltu/adm/venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/paripasviktor/ltu/adm/venv/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 364, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/paripasviktor/ltu/adm/venv/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 364, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"/Users/paripasviktor/ltu/adm/project/utils/data_loading.py\", line 108, in __getitem__\n    mask = self.preprocess(self.mask_values, mask, self.scale, is_mask=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/paripasviktor/ltu/adm/project/utils/data_loading.py\", line 124, in preprocess\n    return self._mask(image, new_size, mask_values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/paripasviktor/ltu/adm/project/utils/data_loading.py\", line 141, in _mask\n    mask[image == value] = i\n    ~~~~^^^^^^^^^^^^^^^^\nIndexError: boolean index did not match indexed array along dimension 0; dimension is 959 but corresponding boolean dimension is 640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x1681f9f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 1690fac50, execution_count=21 error_before_exec=None error_in_exec=Caught IndexError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/Users/paripasviktor/ltu/adm/venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/paripasviktor/ltu/adm/venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = self.dataset.__getitems__(possibly_batched_index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/paripasviktor/ltu/adm/venv/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 364, in __getitems__\n",
      "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/paripasviktor/ltu/adm/venv/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 364, in <listcomp>\n",
      "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
      "            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/paripasviktor/ltu/adm/project/utils/data_loading.py\", line 108, in __getitem__\n",
      "    mask = self.preprocess(self.mask_values, mask, self.scale, is_mask=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/paripasviktor/ltu/adm/project/utils/data_loading.py\", line 124, in preprocess\n",
      "    return self._mask(image, new_size, mask_values)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/paripasviktor/ltu/adm/project/utils/data_loading.py\", line 141, in _mask\n",
      "    mask[image == value] = i\n",
      "    ~~~~^^^^^^^^^^^^^^^^\n",
      "IndexError: boolean index did not match indexed array along dimension 0; dimension is 959 but corresponding boolean dimension is 640\n",
      " info=<ExecutionInfo object at 16b44de10, raw_cell=\"\n",
      "global_step = 0\n",
      "for epoch in range(1, EPOCHS + 1)..\" store_history=True silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;31mTypeError\u001B[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "global_step = 0\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    with tqdm(\n",
    "        total=num_training, desc=f'Epoch {epoch}/{EPOCHS}', unit='img'\n",
    "    ) as progress_bar:\n",
    "        for batch in training_loader:\n",
    "            images, loss, true_masks, predicted_masks = _get_batch_loss(\n",
    "                model, batch, criterion, AUTOMATIC_MIXED_PRECISION\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            grad_scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIPPING)\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update()\n",
    "\n",
    "            progress_bar.update(images.shape[0])\n",
    "            global_step += 1\n",
    "            epoch_loss += loss.item()\n",
    "            experiment.log({'train loss': loss.item(), 'step': global_step, 'epoch': epoch})\n",
    "            progress_bar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "            _evaluate(\n",
    "                validation_loader,\n",
    "                epoch,\n",
    "                num_training,\n",
    "                BATCH_SIZE,\n",
    "                global_step,\n",
    "                scheduler,\n",
    "                optimizer,\n",
    "                images,\n",
    "                true_masks,\n",
    "                predicted_masks,\n",
    "                AUTOMATIC_MIXED_PRECISION,\n",
    "                experiment,\n",
    "            )\n",
    "\n",
    "    if SAVE_CHECKPOINT:\n",
    "        save_checkpoint(model, dataset, checkpoint_directory, epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "CrhP2gYjXvxS",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}